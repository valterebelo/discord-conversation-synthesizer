"""
Timeline module - generates chronological views of conversations.

Shows the evolution of community discussions over time.
"""

import logging
import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Optional
import yaml

logger = logging.getLogger(__name__)


def load_conversation_metadata(vault_path: Path) -> list[dict]:
    """Load metadata from all conversation notes."""
    conversations_dir = vault_path / "conversations"
    notes = []

    if not conversations_dir.exists():
        return notes

    for note_path in conversations_dir.glob("*.md"):
        if note_path.name.startswith("_"):
            continue

        try:
            content = note_path.read_text(encoding="utf-8")

            # Parse frontmatter
            if content.startswith("---"):
                end = content.find("---", 3)
                if end != -1:
                    frontmatter = yaml.safe_load(content[3:end])

                    # Extract summary
                    summary_match = re.search(
                        r'## Summary\s*\n(.*?)(?=\n## |\Z)',
                        content,
                        re.DOTALL
                    )
                    summary = summary_match.group(1).strip()[:200] if summary_match else ""

                    notes.append({
                        "filename": note_path.stem,
                        "title": frontmatter.get("title", note_path.stem),
                        "date": frontmatter.get("date", "unknown"),
                        "participants": frontmatter.get("participants", []),
                        "channel": frontmatter.get("channel", ""),
                        "tags": frontmatter.get("tags", []),
                        "timespan": frontmatter.get("timespan", ""),
                        "summary": summary,
                    })
        except Exception as e:
            logger.warning(f"Failed to load {note_path.name}: {e}")

    # Sort by date
    notes.sort(key=lambda x: x["date"], reverse=True)
    return notes


def generate_timeline(vault_path: Path) -> Path:
    """Generate the main timeline page."""
    notes = load_conversation_metadata(vault_path)

    # Group by month
    by_month: dict[str, list[dict]] = defaultdict(list)
    for note in notes:
        if note["date"] and note["date"] != "unknown":
            month = note["date"][:7]  # YYYY-MM
            by_month[month].append(note)

    lines = [
        "---",
        "title: Timeline",
        "type: timeline",
        f'updated: "{datetime.now().strftime("%Y-%m-%d")}"',
        "---",
        "",
        "# Community Timeline",
        "",
        "A chronological view of all discussions.",
        "",
        f"**{len(notes)} conversations** from **{len(by_month)} months**",
        "",
    ]

    # Generate month sections
    for month in sorted(by_month.keys(), reverse=True):
        month_notes = by_month[month]

        # Format month header
        try:
            month_dt = datetime.strptime(month, "%Y-%m")
            month_label = month_dt.strftime("%B %Y")
        except:
            month_label = month

        lines.append(f"## {month_label}")
        lines.append("")

        for note in month_notes:
            # Format each conversation
            tags_str = " ".join(f"`{t}`" for t in note["tags"][:3])
            participant_count = len(note["participants"])

            lines.append(f"### [{note['date']}] {note['title']}")
            lines.append("")
            if note["timespan"]:
                lines.append(f"*{note['timespan']}* · {participant_count} participants")
            else:
                lines.append(f"*{participant_count} participants*")
            lines.append("")
            if note["summary"]:
                lines.append(f"> {note['summary'][:150]}...")
            lines.append("")
            lines.append(f"Tags: {tags_str}")
            lines.append("")
            lines.append(f"→ [[{note['filename']}|Read full discussion]]")
            lines.append("")
            lines.append("---")
            lines.append("")

    lines.extend([
        "",
        "*Auto-generated by Discord Conversation Synthesizer*",
    ])

    # Write timeline
    timeline_path = vault_path / "timeline.md"
    timeline_path.write_text("\n".join(lines), encoding="utf-8")
    logger.info(f"Generated timeline with {len(notes)} conversations")

    return timeline_path


def generate_weekly_view(vault_path: Path) -> Path:
    """Generate a weekly breakdown view."""
    notes = load_conversation_metadata(vault_path)

    # Group by week
    by_week: dict[str, list[dict]] = defaultdict(list)
    for note in notes:
        if note["date"] and note["date"] != "unknown":
            try:
                dt = datetime.strptime(note["date"], "%Y-%m-%d")
                # Get ISO week
                year, week, _ = dt.isocalendar()
                week_key = f"{year}-W{week:02d}"
                by_week[week_key].append(note)
            except:
                pass

    lines = [
        "---",
        "title: Weekly View",
        "type: timeline",
        "---",
        "",
        "# Weekly Breakdown",
        "",
        "Conversations organized by week.",
        "",
    ]

    for week in sorted(by_week.keys(), reverse=True)[:12]:  # Last 12 weeks
        week_notes = by_week[week]

        # Calculate week date range
        year, week_num = int(week[:4]), int(week[6:])
        try:
            from datetime import timedelta
            first_day = datetime.strptime(f"{year}-W{week_num}-1", "%Y-W%W-%w")
            last_day = first_day + timedelta(days=6)
            week_label = f"{first_day.strftime('%b %d')} - {last_day.strftime('%b %d, %Y')}"
        except:
            week_label = week

        lines.append(f"## {week_label}")
        lines.append("")
        lines.append(f"*{len(week_notes)} conversations*")
        lines.append("")

        # Topic summary for the week
        all_tags = []
        for note in week_notes:
            all_tags.extend(note["tags"])
        tag_counts = defaultdict(int)
        for tag in all_tags:
            tag_counts[tag] += 1
        top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]

        if top_tags:
            lines.append("**Hot topics:** " + ", ".join(f"`{t}`" for t, _ in top_tags))
            lines.append("")

        for note in week_notes:
            lines.append(f"- **{note['date']}** [[{note['filename']}|{note['title'][:50]}{'...' if len(note['title']) > 50 else ''}]]")

        lines.append("")

    lines.extend([
        "",
        "[[timeline|← Full Timeline]]",
    ])

    weekly_path = vault_path / "weekly.md"
    weekly_path.write_text("\n".join(lines), encoding="utf-8")
    logger.info(f"Generated weekly view")

    return weekly_path


def generate_topic_evolution(vault_path: Path) -> Path:
    """Generate a view showing how topics evolved over time."""
    notes = load_conversation_metadata(vault_path)

    # Track topic frequency by month
    topic_by_month: dict[str, dict[str, int]] = defaultdict(lambda: defaultdict(int))

    for note in notes:
        if note["date"] and note["date"] != "unknown":
            month = note["date"][:7]
            for tag in note["tags"]:
                topic_by_month[month][tag] += 1

    # Find top topics overall
    all_tags = defaultdict(int)
    for note in notes:
        for tag in note["tags"]:
            all_tags[tag] += 1
    top_topics = [t for t, _ in sorted(all_tags.items(), key=lambda x: x[1], reverse=True)[:10]]

    lines = [
        "---",
        "title: Topic Evolution",
        "type: timeline",
        "---",
        "",
        "# Topic Evolution",
        "",
        "How discussion topics have changed over time.",
        "",
        "## Top Topics Overall",
        "",
    ]

    for tag in top_topics:
        count = all_tags[tag]
        lines.append(f"- **{tag.replace('-', ' ').title()}**: {count} conversations")

    lines.append("")
    lines.append("## Monthly Breakdown")
    lines.append("")

    for month in sorted(topic_by_month.keys(), reverse=True):
        month_topics = topic_by_month[month]

        try:
            month_dt = datetime.strptime(month, "%Y-%m")
            month_label = month_dt.strftime("%B %Y")
        except:
            month_label = month

        top_month_topics = sorted(month_topics.items(), key=lambda x: x[1], reverse=True)[:5]

        lines.append(f"### {month_label}")
        lines.append("")
        for tag, count in top_month_topics:
            bar = "█" * min(count, 10)
            lines.append(f"- `{tag}` {bar} ({count})")
        lines.append("")

    lines.extend([
        "",
        "[[timeline|← Full Timeline]]",
    ])

    evolution_path = vault_path / "topic-evolution.md"
    evolution_path.write_text("\n".join(lines), encoding="utf-8")
    logger.info(f"Generated topic evolution view")

    return evolution_path


def generate_all_timeline_views(vault_path: Path) -> list[Path]:
    """Generate all timeline-related views."""
    paths = []

    paths.append(generate_timeline(vault_path))
    paths.append(generate_weekly_view(vault_path))
    paths.append(generate_topic_evolution(vault_path))

    return paths


if __name__ == "__main__":
    import sys

    logging.basicConfig(level=logging.INFO)

    vault_path = Path(__file__).parent.parent / "output"
    paths = generate_all_timeline_views(vault_path)

    print(f"\nGenerated timeline views:")
    for p in paths:
        print(f"  - {p.name}")
